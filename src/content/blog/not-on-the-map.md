---
title: "Not on the Map"
description: "On smart lockers, food kiosks, and the invisible infrastructure that disappears when we optimize for what we can measure."
pubDate: "2026-02-20"
draft: false
tags: ["service design", "systems thinking", "efficiency", "human discretion", "automation"]
author: "Daniel Fridgren"
heroImage: "/images/blog-images/postnord-paketbox.jpg"
heroImageCaption: "Photo by PostNord"
---

Nobody decided to make things harder for old people at package lockers. The decision that was made, somewhere in a meeting about a new solution, was surely to make things more accessible and efficient. The smart package locker is more efficient, the Bluetooth handshake is seamless, the app that replaces the person behind the counter is an improvement, at least by every metric that gets measured.

What gets lost in the process of streamlining for efficiency?

I thought about this a while ago, after helping an old man outside a PostNord smart locker. With the bewilderment of someone who just realized the rules changed while they weren't there, he showed me his phone, where all he had was the SMS he’d got. He was used to being able to say a four-digit identifier to a person behind a counter. Now there was no counter, no person, and no four digits. Instead he needed an app, but had forgotten his App Store password. By the time we got the locker open, he could have walked to the old pickup point and back home again.

Service design maps pain points and friction, and treats both as problems to solve: Find what slows people down, remove it. It’s a useful instinct. But efficiency also smuggles in a value system, even though pretending to be value neutral.

When service design is commissioned by an organization, it usually serves that organization's goals, and those goals are typically framed in terms of efficiency or cost: Reduce call volume, increase throughput, lower cost-per-transaction, etc. The lens gets bent toward those ends. And the focal points are what is quantifiable by the organization. The rest falls outside of view.

"More efficient" sounds like a neutral, logical progression. But it isn't. It encodes a set of choices. For instance that human labor is a cost to minimize, and time spent in unmediated human contact is wasteful and should be reduced.

The old man at the smart package locker lost something the efficient solution never accounted for.

At the old pickup point, the person behind the desk knew him. Maybe not by name, but by face the way regulars are known. He would get the package, and a few words exchanged about the weather. Not even a one minute encounter. <a href="https://sv.wikipedia.org/wiki/Jonna_Bornemark" target="_blank" rel="noopener noreferrer">Jonna Bornemark</a> calls this <a href="https://www.adlibris.com/sv/bok/det-omatbaras-renassans-en-uppgorelse-med-pedanternas-varldsherravalde-9789188659170" target="_blank" rel="noopener noreferrer">the immeasurable</a>: value that generates no quantifiable data, and thus looks like nothing from the outside.

On a recent visit to IKEA in another town, we found that you no longer say your order to a person. You use a digital kiosk with fixed menu options. We usually adjust our food order due to allergies and preferences, but the interface was too rigid for our needs. So we had to find a member of staff, explain the situation, and ask them to write a special note to the kitchen. Taking considerably longer than just asking would have. The system was faster for everyone it had anticipated. For us it was the opposite.

What gets automated away isn't easily quantifiable. But it is possible to observe and attend to. Take human discretion: the capacity to read a situation and respond to what's actually there rather than what the system expects. The clerk who rerouted your flight when you explained why you had to make the connection. The pharmacist who noticed something in your prescription that the algorithm didn't flag. It is a kind of invisible infrastructure nobody actively decided to remove, but once the person behind the counter is replaced, so is everything they were quietly carrying.

The package locker works. The food ordering screen works. The efficiency measured in throughput is real. What's harder to see is what they've retired, and harder still is that once it's gone, we simply adjust to its absence. We call it progress.

So what would it mean to design differently? Not to reject technology or automation, that's not the point. The point is to ask a few questions before the decisions are made, while there is still something to preserve.

The first question is about what's *actually* there. While mapping the user journey, ask what the interaction contains that the map won't show. The hospital receptionist who notices you've been waiting too long and catches someone's eye on your behalf. The GP visit where a regular and a doctor have built a shorthand over the years that makes the consultation more information dense. What happens between the scripted steps is far from being just irrelevancies. It’s accumulated knowledge, the capacity to deviate from protocol when the situation demands it. If your journey map takes no account of judgment, presence, or the knowledge that accumulates between people, you're not mapping the service, but its skeleton.

The second question is about what atrophies. <a href="https://nautil.us/will-ai-harm-us-better-to-ask-how-well-reckon-with-our-hybrid-nature-236098/" target="_blank" rel="noopener noreferrer">David Krakauer</a> distinguishes between tools that extend human capability and tools that replace it. The difference matters because replacement isn't neutral. A child who grows up ordering food from a screen doesn't just lack practice at speaking to strangers. They grow up in a world where that wasn't required of them. The question isn't just "can we automate this?" but "what happens to the muscle we're removing, and do we want to live in a world where it's gone?”.

The third question is: who gets to deviate? Every system is designed for a user it has imagined. The imagined user of the PostNord locker has a smartphone, a certain app, BankID. This is not the old man. The imagined user of the IKEA ordering screen eats from the preset menu. That's not my daughter. When they encountered the system, there was no one on the other side who could handle the situation and possible deviation gracefully.

The question isn't whether to use technology. It's whether the thing you're augmenting or automating was also doing something else, and whether that something else was worth keeping.

Most efficiency arguments don't ask these questions. They measure what they can see, optimize for it, and call what's left behind irrelevant. 

The old man got his package in the end. I helped him because I happened to be there. But ”someone happened to be there” is not a design principle. The person behind the counter was. We just didn’t see it that way until they were gone.